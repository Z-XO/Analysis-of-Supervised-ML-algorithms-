{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries;\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set_style('white')\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from numpy import genfromtxt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import load_digits, make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, StandardScaler \n",
    "from sklearn.preprocessing import RobustScaler, Normalizer, QuantileTransformer, PowerTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from random import choices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fireWall = pd.read_csv('log2.csv')\n",
    "\n",
    "fireWallXData = fireWall[['Source Port', 'Destination Port','NAT Source Port',\n",
    "                         'NAT Destination Port','Bytes','Bytes Sent','Bytes Received','Packets',\n",
    "                        'Elapsed Time (sec)','pkts_sent','pkts_received']]\n",
    "fireWallyData = fireWall[['Action']]\n",
    "\n",
    "X = fireWallXData.iloc[:,0:10]\n",
    "y = fireWallyData.iloc[:,0]\n",
    "\n",
    "\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "\n",
    "#print(fireWall.shape)\n",
    "\n",
    "FireWALLData = pd.concat([X, y], axis=1)\n",
    "print(FireWALLData.shape)\n",
    "\n",
    "newX = FireWALLData.iloc[:,0:9]\n",
    "newy = FireWALLData.iloc[:,10]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encodeLabel = LabelEncoder()\n",
    "newy = encodeLabel.fit_transform(newy)\n",
    "print(newy)\n",
    "\n",
    "\n",
    "FireWALLData.loc[FireWALLData['Action'] == 0, 'Action'] = 1\n",
    "FireWALLData.loc[FireWALLData['Action'] == 1, 'Action'] = 0\n",
    "FireWALLData.loc[FireWALLData['Action'] == 2, 'Action'] = 1\n",
    "FireWALLData.loc[FireWALLData['Action'] == 3, 'Action'] = 0\n",
    "\n",
    "newy = FireWALLData.iloc[:,10]\n",
    "\n",
    "FireWALLData.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( newX, newy, test_size=60000, random_state=1738)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINE TRIAL ONE ON Fire Wall  DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ITERATIONS = 1\n",
    "for i in range(1):\n",
    "    #For reach \"trial\", randomly select 5000 data points\n",
    "    random5000DataPoints = FireWALLData.sample(n = 5000, replace = True)    \n",
    "    #From that 5000, create x set and y set\n",
    "    xSet = random5000DataPoints.iloc[:,0:9].values\n",
    "    ySet = random5000DataPoints.iloc[:,10].values\n",
    "    ySet = encodeLabel.fit_transform(ySet)\n",
    "    \n",
    "    pipe = Pipeline([('std', StandardScaler()),('classifier', svm.SVC(max_iter=5000,probability=True))])\n",
    "\n",
    "    search_space = [\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['rbf'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['sigmoid'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                \n",
    "                'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                'classifier__kernel': ['poly'],\n",
    "                'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['linear'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]}, \n",
    "                \n",
    "                ]\n",
    "    \n",
    "    #'precision_micro','roc_auc_ovo','jaccard','neg_log_loss'] JACCARD DOES NOT WORK FOR NON BINARY?\n",
    "    runHyperParamSearch = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=2), \n",
    "                          scoring=['recall_micro','f1_micro','roc_auc_ovo','neg_log_loss'], \n",
    "                          refit=False, verbose=10, n_jobs = -1)\n",
    "    TRIAL_1_SVM = runHyperParamSearch.fit(xSet, ySet)\n",
    "    print(\"---------------------------------TRIAL ONE RESULTS ---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRIAL_1_SVM.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------TRIAL ONE NEG LOG LOSS RESULTS ---------------------------------------------\")\n",
    "TRIAL_1_SVM.cv_results_['rank_test_neg_log_loss']\n",
    "TRIAL_1_SVM.cv_results_['params'][ np.argmin(TRIAL_1_SVM.cv_results_['rank_test_neg_log_loss']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------TRIAL ONE F1 RESULTS ---------------------------------------------\")\n",
    "TRIAL_1_SVM.cv_results_['rank_test_f1_micro']\n",
    "TRIAL_1_SVM.cv_results_['params'][ np.argmin(TRIAL_1_SVM.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------TRIAL ONE ROC AUC RESULTS ---------------------------------------------\")\n",
    "TRIAL_1_SVM.cv_results_['rank_test_roc_auc_ovo']\n",
    "TRIAL_1_SVM.cv_results_['params'][ np.argmin(TRIAL_1_SVM.cv_results_['rank_test_roc_auc_ovo']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best NEG LOG LOSS results to train on test set, \n",
    "p = TRIAL_1_SVM.cv_results_['params'][ np.argmin(TRIAL_1_SVM.cv_results_['rank_test_neg_log_loss']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train__neg_log_loss = pipe.predict(X_train)\n",
    "y_pred_test_neg_log_loss = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 1 svm using best NEG LOG LOSS hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_neg_log_loss)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best F1 results to train on test set, LR_Trial 1\n",
    "p = TRIAL_1_SVM.cv_results_['params'][ np.argmin(TRIAL_1_SVM.cv_results_['rank_test_f1_micro']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_f1 = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 1 svm using best F1 hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_f1)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best ROC_AUC results to train on test set, LR_Trial 1\n",
    "p  = TRIAL_1_SVM.cv_results_['params'][ np.argmin(TRIAL_1_SVM.cv_results_['rank_test_roc_auc_ovo']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_roc_auc = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 1 svm using best ROC_AUC hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_roc_auc)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINE TRIAL TWO ON Fire Wall  DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ITERATIONS = 1\n",
    "for i in range(1):\n",
    "    #For reach \"trial\", randomly select 5000 data points\n",
    "    random5000DataPoints = FireWALLData.sample(n = 5000, replace = True)\n",
    "    #From that 5000, create x set and y set\n",
    "    xSet = random5000DataPoints.iloc[:,0:9].values\n",
    "    ySet = random5000DataPoints.iloc[:,10].values\n",
    "    ySet = encodeLabel.fit_transform(ySet)\n",
    "    \n",
    "    pipe = Pipeline([('std', MinMaxScaler(feature_range = (0, 1))),('classifier', svm.SVC(max_iter=5000,probability=True))])\n",
    "\n",
    "    search_space = [\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['rbf'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['sigmoid'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                \n",
    "                'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                'classifier__kernel': ['poly'],\n",
    "                'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['linear'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]}, \n",
    "                \n",
    "                ]\n",
    "    \n",
    "    #'precision_micro','roc_auc_ovo','jaccard','neg_log_loss'] JACCARD DOES NOT WORK FOR NON BINARY?\n",
    "    runHyperParamSearch = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=2), \n",
    "                          scoring=['recall_micro','f1_micro','roc_auc_ovo','neg_log_loss'], \n",
    "                          refit=False, verbose=10, n_jobs = -1)\n",
    "    TRIAL_2_SVM = runHyperParamSearch.fit(xSet, ySet)\n",
    "    print(\"---------------------------------TRIAL TWO RESULTS ---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_2_SVM.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------TRIAL TWO NEG LOG LOSS RESULTS ---------------------------------------------\")\n",
    "TRIAL_2_SVM.cv_results_['rank_test_neg_log_loss']\n",
    "TRIAL_2_SVM.cv_results_['params'][ np.argmin(TRIAL_2_SVM.cv_results_['rank_test_neg_log_loss']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------TRIAL TWO F1 RESULTS ---------------------------------------------\")\n",
    "TRIAL_2_SVM.cv_results_['rank_test_f1_micro']\n",
    "TRIAL_2_SVM.cv_results_['params'][ np.argmin(TRIAL_2_SVM.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------TRIAL TWO ROC AUC RESULTS ---------------------------------------------\")\n",
    "TRIAL_2_SVM.cv_results_['rank_test_roc_auc_ovo']\n",
    "TRIAL_2_SVM.cv_results_['params'][ np.argmin(TRIAL_2_SVM.cv_results_['rank_test_roc_auc_ovo']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best NEG LOG LOSS results to train on test set, \n",
    "p = TRIAL_2_SVM.cv_results_['params'][ np.argmin(TRIAL_2_SVM.cv_results_['rank_test_neg_log_loss']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train__neg_log_loss = pipe.predict(X_train)\n",
    "y_pred_test_neg_log_loss = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 2 svm using best NEG LOG LOSS hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_neg_log_loss)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best F1 results to train on test set, LR_Trial 1\n",
    "p = TRIAL_2_SVM.cv_results_['params'][ np.argmin(TRIAL_2_SVM.cv_results_['rank_test_f1_micro']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_f1 = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 2 svm using best F1 hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_f1)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best ROC_AUC results to train on test set, LR_Trial 1\n",
    "p  = TRIAL_2_SVM.cv_results_['params'][ np.argmin(TRIAL_2_SVM.cv_results_['rank_test_roc_auc_ovo']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_roc_auc = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 2 svm using best ROC_AUC hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_roc_auc)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINE TRIAL THREE ON Fire Wall  DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ITERATIONS = 1\n",
    "for i in range(1):\n",
    "    #For reach \"trial\", randomly select 5000 data points\n",
    "    random5000DataPoints = FireWALLData.sample(n = 5000, replace = True)\n",
    "    #From that 5000, create x set and y set\n",
    "    xSet = random5000DataPoints.iloc[:,0:9].values\n",
    "    ySet = random5000DataPoints.iloc[:,10].values\n",
    "    ySet = encodeLabel.fit_transform(ySet)\n",
    "    # Run GridSearch to find best hyperparameters per 5000 data points \n",
    "    \n",
    "    pipe = Pipeline([('std', StandardScaler()),('classifier', svm.SVC(max_iter=5000,probability=True))])\n",
    "\n",
    "    search_space = [\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['rbf'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['sigmoid'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                \n",
    "                'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                'classifier__kernel': ['poly'],\n",
    "                'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['linear'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]}, \n",
    "                \n",
    "                ]\n",
    "    \n",
    "    #'precision_micro','roc_auc_ovo','jaccard','neg_log_loss'] JACCARD DOES NOT WORK FOR NON BINARY?\n",
    "    runHyperParamSearch = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=2), \n",
    "                          scoring=['recall_micro','f1_micro','roc_auc_ovo','neg_log_loss'], \n",
    "                          refit=False, verbose=10, n_jobs = -1)\n",
    "    TRIAL_3_SVM = runHyperParamSearch.fit(xSet, ySet)\n",
    "    print(\"---------------------------------TRIAL THREE RESULTS ---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_3_SVM.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------TRIAL THREE NEG LOG LOSS RESULTS ---------------------------------------------\")\n",
    "TRIAL_3_SVM.cv_results_['rank_test_neg_log_loss']\n",
    "TRIAL_3_SVM.cv_results_['params'][ np.argmin(TRIAL_3_SVM.cv_results_['rank_test_neg_log_loss']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------TRIAL THREE F1 RESULTS ---------------------------------------------\")\n",
    "TRIAL_3_SVM.cv_results_['rank_test_f1_micro']\n",
    "TRIAL_3_SVM.cv_results_['params'][ np.argmin(TRIAL_3_SVM.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------TRIAL THREE ROC AUC RESULTS ---------------------------------------------\")\n",
    "TRIAL_3_SVM.cv_results_['rank_test_roc_auc_ovo']\n",
    "TRIAL_3_SVM.cv_results_['params'][ np.argmin(TRIAL_3_SVM.cv_results_['rank_test_roc_auc_ovo']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best NEG LOG LOSS results to train on test set, \n",
    "p = TRIAL_3_SVM.cv_results_['params'][ np.argmin(TRIAL_3_SVM.cv_results_['rank_test_neg_log_loss']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train__neg_log_loss = pipe.predict(X_train)\n",
    "y_pred_test_neg_log_loss = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 3 svm using best NEG LOG LOSS hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_neg_log_loss)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best F1 results to train on test set, LR_Trial 1\n",
    "p = TRIAL_3_SVM.cv_results_['params'][ np.argmin(TRIAL_3_SVM.cv_results_['rank_test_f1_micro']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_f1 = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 3 svm using best F1 hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_f1)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best ROC_AUC results to train on test set, LR_Trial 1\n",
    "p  = TRIAL_3_SVM.cv_results_['params'][ np.argmin(TRIAL_3_SVM.cv_results_['rank_test_roc_auc_ovo']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_roc_auc = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 3 svm using best ROC_AUC hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_roc_auc)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINE TRIAL FOUR ON Fire Wall  DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 1\n",
    "for i in range(1):\n",
    "    #For reach \"trial\", randomly select 5000 data points\n",
    "    random5000DataPoints = FireWALLData.sample(n = 5000, replace = True)\n",
    "    #From that 5000, create x set and y set\n",
    "    xSet = random5000DataPoints.iloc[:,0:9].values\n",
    "    ySet = random5000DataPoints.iloc[:,10].values\n",
    "    ySet = encodeLabel.fit_transform(ySet)\n",
    "    # Run GridSearch to find best hyperparameters per 5000 data points \n",
    "    \n",
    "    pipe = Pipeline([('std', StandardScaler()),('classifier', svm.SVC(max_iter=5000,probability=True))])\n",
    "\n",
    "    search_space = [\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['rbf'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['sigmoid'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                \n",
    "                'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                'classifier__kernel': ['poly'],\n",
    "                'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['linear'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]}, \n",
    "                \n",
    "                ]\n",
    "    \n",
    "    #'precision_micro','roc_auc_ovo','jaccard','neg_log_loss'] JACCARD DOES NOT WORK FOR NON BINARY?\n",
    "    runHyperParamSearch = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=2), \n",
    "                          scoring=['recall_micro','f1_micro','roc_auc_ovo','neg_log_loss'], \n",
    "                          refit=False, verbose=10, n_jobs = -1)\n",
    "    TRIAL_4_SVM = runHyperParamSearch.fit(xSet, ySet)\n",
    "    print(\"---------------------------------TRIAL FOUR RESULTS ---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_4_SVM.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------TRIAL FOUR NEG LOG LOSS RESULTS ---------------------------------------------\")\n",
    "TRIAL_4_SVM.cv_results_['rank_test_neg_log_loss']\n",
    "TRIAL_4_SVM.cv_results_['params'][ np.argmin(TRIAL_4_SVM.cv_results_['rank_test_neg_log_loss']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------TRIAL FOUR F1 RESULTS ---------------------------------------------\")\n",
    "TRIAL_4_SVM.cv_results_['rank_test_f1_micro']\n",
    "TRIAL_4_SVM.cv_results_['params'][ np.argmin(TRIAL_4_SVM.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------TRIAL FOUR ROC AUC RESULTS ---------------------------------------------\")\n",
    "TRIAL_4_SVM.cv_results_['rank_test_roc_auc_ovo']\n",
    "TRIAL_4_SVM.cv_results_['params'][ np.argmin(TRIAL_4_SVM.cv_results_['rank_test_roc_auc_ovo']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best NEG LOG LOSS results to train on test set, \n",
    "p = TRIAL_4_SVM.cv_results_['params'][ np.argmin(TRIAL_4_SVM.cv_results_['rank_test_neg_log_loss']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train__neg_log_loss = pipe.predict(X_train)\n",
    "y_pred_test_neg_log_loss = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 4 svm using best NEG LOG LOSS hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_neg_log_loss)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best F1 results to train on test set, LR_Trial 1\n",
    "p = TRIAL_4_SVM.cv_results_['params'][ np.argmin(TRIAL_4_SVM.cv_results_['rank_test_f1_micro']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_f1 = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 4 svm using best F1 hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_f1)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best ROC_AUC results to train on test set, LR_Trial 1\n",
    "p  = TRIAL_4_SVM.cv_results_['params'][ np.argmin(TRIAL_4_SVM.cv_results_['rank_test_roc_auc_ovo']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_roc_auc = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 4 svm using best ROC_AUC hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_roc_auc)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINE TRIAL FIVE ON Fire Wall  DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ITERATIONS = 1\n",
    "for i in range(1):\n",
    "    #For reach \"trial\", randomly select 5000 data points\n",
    "    random5000DataPoints = FireWALLData.sample(n = 5000, replace = True)\n",
    "    #From that 5000, create x set and y set\n",
    "    xSet = random5000DataPoints.iloc[:,0:9].values\n",
    "    ySet = random5000DataPoints.iloc[:,10].values\n",
    "    ySet = encodeLabel.fit_transform(ySet)\n",
    "    # Run GridSearch to find best hyperparameters per 5000 data points\n",
    "    \n",
    "    pipe = Pipeline([('std', StandardScaler()),('classifier', svm.SVC(max_iter=5000,probability=True))])\n",
    "\n",
    "    search_space = [\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['rbf'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['sigmoid'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                \n",
    "                {\n",
    "                \n",
    "                'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                'classifier__kernel': ['poly'],\n",
    "                'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]},\n",
    "                {\n",
    "                 \n",
    "                 'classifier': [svm.SVC(max_iter=7000,probability=True)],\n",
    "                 'classifier__kernel': ['linear'],\n",
    "                 'classifier__gamma': [1e-8,1e-7,1e-6, 1e-5, 1e-4, 1e-3,1e-2,1e-1,1e-0],\n",
    "                 'classifier__C': [.0010,.010,.10, 1, 10, 100, 1000,10000,100000]}, \n",
    "                \n",
    "                ]\n",
    "    \n",
    "    #'precision_micro','roc_auc_ovo','jaccard','neg_log_loss'] JACCARD DOES NOT WORK FOR NON BINARY?\n",
    "    runHyperParamSearch = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=2), \n",
    "                          scoring=['recall_micro','f1_micro','roc_auc_ovo','neg_log_loss'], \n",
    "                          refit=False, verbose=10, n_jobs = -1)\n",
    "    TRIAL_5_SVM = runHyperParamSearch.fit(xSet, ySet)\n",
    "    print(\"---------------------------------TRIAL FIVE RESULTS ---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_5_SVM.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------TRIAL FIVE NEG LOG LOSS RESULTS ---------------------------------------------\")\n",
    "TRIAL_5_SVM.cv_results_['rank_test_neg_log_loss']\n",
    "TRIAL_5_SVM.cv_results_['params'][ np.argmin(TRIAL_5_SVM.cv_results_['rank_test_neg_log_loss']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------TRIAL FIVE F1 RESULTS ---------------------------------------------\")\n",
    "TRIAL_5_SVM.cv_results_['rank_test_f1_micro']\n",
    "TRIAL_5_SVM.cv_results_['params'][ np.argmin(TRIAL_5_SVM.cv_results_['rank_test_f1_micro']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------TRIAL FIVE ROC AUC RESULTS ---------------------------------------------\")\n",
    "TRIAL_5_SVM.cv_results_['rank_test_roc_auc_ovo']\n",
    "TRIAL_5_SVM.cv_results_['params'][ np.argmin(TRIAL_5_SVM.cv_results_['rank_test_roc_auc_ovo']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best NEG LOG LOSS results to train on test set, \n",
    "p = TRIAL_5_SVM.cv_results_['params'][ np.argmin(TRIAL_5_SVM.cv_results_['rank_test_neg_log_loss']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train__neg_log_loss = pipe.predict(X_train)\n",
    "y_pred_test_neg_log_loss = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 5 svm using best NEG LOG LOSS hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_neg_log_loss)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best F1 results to train on test set, LR_Trial 1\n",
    "p = TRIAL_5_SVM.cv_results_['params'][ np.argmin(TRIAL_5_SVM.cv_results_['rank_test_f1_micro']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_f1 = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 5 svm using best F1 hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_f1)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "# Using Best hyperparameters of best ROC_AUC results to train on test set, LR_Trial 1\n",
    "p  = TRIAL_5_SVM.cv_results_['params'][ np.argmin(TRIAL_5_SVM.cv_results_['rank_test_roc_auc_ovo']) ]\n",
    "pipe.set_params(**p)\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred_train_roc_auc = pipe.predict(X_train)\n",
    "y_pred_test_roc_auc = pipe.predict(X_test)\n",
    "print('Accuracy of Trial 5 svm using best ROC_AUC hyperparameters :'\n",
    "      + str(accuracy_score(y_test,y_pred_test_roc_auc)))\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
